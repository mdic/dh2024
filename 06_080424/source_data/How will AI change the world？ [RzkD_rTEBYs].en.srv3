<?xml version="1.0" encoding="utf-8" ?><timedtext format="3">
<body>
<p t="6335" d="2169">In the coming years, 
artificial intelligence</p>
<p t="8504" d="4004">is probably going to change your life, 
and likely the entire world.</p>
<p t="12592" d="3128">But people have a hard time
agreeing on exactly how.</p>
<p t="15720" d="3211">The following are excerpts 
from a World Economic Forum interview</p>
<p t="18931" d="3796">where renowned computer science professor 
and AI expert Stuart Russell</p>
<p t="22727" d="2586">helps separate the sense 
from the nonsense.</p>
<p t="25313" d="3754">There’s a big difference between asking
a human to do something</p>
<p t="29067" d="3461">and giving that as the objective
to an AI system.</p>
<p t="32528" d="2628">When you ask a human to get
you a cup of coffee,</p>
<p t="35156" d="2586">you don’t mean this should be 
their life’s mission,</p>
<p t="37742" d="1960">and nothing else in the universe matters.</p>
<p t="39702" d="2586">Even if they have to kill everybody else
in Starbucks</p>
<p t="42288" d="2836">to get you the coffee before it closes—
they should do that.</p>
<p t="45124" d="1627">No, that’s not what you mean.</p>
<p t="46751" d="2294">All the other things that
we mutually care about,</p>
<p t="49045" d="2169">they should factor
into your behavior as well.</p>
<p t="51214" d="3169">And the problem with the way 
we build AI systems now</p>
<p t="54383" d="1627">is we give them a fixed objective.</p>
<p t="56010" d="3545">The algorithms require us
to specify everything in the objective.</p>
<p t="59555" d="3420">And if you say, can we fix the
acidification of the oceans?</p>
<p t="62975" d="4046">Yeah, you could have a catalytic reaction
that does that extremely efficiently,</p>
<p t="67021" d="3253">but it consumes a quarter 
of the oxygen in the atmosphere,</p>
<p t="70274" d="3712">which would apparently cause us to die
fairly slowly and unpleasantly</p>
<p t="73986" d="1752">over the course of several hours.</p>
<p t="75780" d="3211">So, how do we avoid this problem?</p>
<p t="78991" d="4088">You might say, okay, well, just be more
careful about specifying the objective—</p>
<p t="83079" d="2544">don’t forget the atmospheric oxygen.</p>
<p t="85873" d="3545">And then, of course, some side effect
of the reaction in the ocean</p>
<p t="89418" d="1377">poisons all the fish.</p>
<p t="90795" d="2669">Okay, well I meant don’t kill
the fish either.</p>
<p t="93464" d="1919">And then, well, what about
the seaweed?</p>
<p t="95383" d="2961">Don’t do anything that’s going
to cause all the seaweed to die.</p>
<p t="98344" d="1210">And on and on and on.</p>
<p t="99679" d="3920">And the reason that we don’t have to do
that with humans is that</p>
<p t="103599" d="4505">humans often know that they don’t know 
all the things that we care about.</p>
<p t="108354" d="2961">If you ask a human to get you
a cup of coffee,</p>
<p t="111315" d="2878">and you happen to be 
in the Hotel George Sand in Paris,</p>
<p t="114193" d="2628">where the coffee is 13 euros a cup,</p>
<p t="116821" d="4171">it’s entirely reasonable to come
back and say, well, it’s 13 euros,</p>
<p t="120992" d="2961">are you sure you want it, 
or I could go next door and get one?</p>
<p t="123953" d="2878">And it’s a perfectly normal thing
for a person to do.</p>
<p t="127039" d="3003">To ask, I’m going to repaint your house—</p>
<p t="130042" d="3337">is it okay if I take off the drainpipes
and then put them back?</p>
<p t="133504" d="3128">We don&#39;t think of this as a terribly
sophisticated capability,</p>
<p t="136632" d="3087">but AI systems don’t have it 
because the way we build them now,</p>
<p t="139719" d="1793">they have to know the full objective.</p>
<p t="141721" d="3753">If we build systems that know that 
they don’t know what the objective is,</p>
<p t="145474" d="2586">then they start to exhibit
these behaviors,</p>
<p t="148060" d="4046">like asking permission before getting rid
of all the oxygen in the atmosphere.</p>
<p t="152565" d="3378">In all these senses, 
control over the AI system</p>
<p t="155943" d="4463">comes from the machine’s uncertainty 
about what the true objective is.</p>
<p t="161282" d="3086">And it’s when you build machines that
believe with certainty</p>
<p t="164368" d="1418">that they have the objective,</p>
<p t="165786" d="2753">that’s when you get this
sort of psychopathic behavior.</p>
<p t="168539" d="2127">And I think we see 
the same thing in humans.</p>
<p t="170750" d="4254">What happens when general purpose AI
hits the real economy?</p>
<p t="175379" d="3587">How do things change? Can we adapt?</p>
<p t="179175" d="1835">This is a very old point.</p>
<p t="181010" d="3587">Amazingly, Aristotle actually has
a passage where he says,</p>
<p t="184597" d="3045">look, if we had fully automated 
weaving machines</p>
<p t="187642" d="3837">and plectrums that could pluck the lyre 
and produce music without any humans,</p>
<p t="191604" d="2002">then we wouldn’t need any workers.</p>
<p t="193814" d="2878">That idea, which I think it was Keynes</p>
<p t="196692" d="2836">who called it technological unemployment 
in 1930,</p>
<p t="199528" d="1919">is very obvious to people.</p>
<p t="201447" d="3086">They think, yeah, of course, 
if the machine does the work,</p>
<p t="204533" d="1669">then I&#39;m going to be unemployed.</p>
<p t="206369" d="3503">You can think about the warehouses 
that companies are currently operating</p>
<p t="209872" d="2711">for e-commerce, 
they are half automated.</p>
<p t="212583" d="4046">The way it works is that an old warehouse—
where you’ve got tons of stuff piled up</p>
<p t="216629" d="2461">all over the place 
and humans go and rummage around</p>
<p t="219090" d="1877">and then bring it back and send it off—</p>
<p t="220967" d="3586">there’s a robot who goes
and gets the shelving unit</p>
<p t="224553" d="1919">that contains the thing that you need,</p>
<p t="226472" d="3629">but the human has to pick the object 
out of the bin or off the shelf,</p>
<p t="230101" d="1877">because that’s still too difficult.</p>
<p t="232019" d="2002">But, at the same time,</p>
<p t="234021" d="3921">would you make a robot that is accurate
enough to be able to pick</p>
<p t="237942" d="4338">pretty much any object within a very wide 
variety of objects that you can buy?</p>
<p t="242280" d="4004">That would, at a stroke, 
eliminate 3 or 4 million jobs?</p>
<p t="246409" d="3336">There&#39;s an interesting story
that E.M. Forster wrote,</p>
<p t="249745" d="3504">where everyone is entirely
machine dependent.</p>
<p t="253499" d="3754">The story is really about the
fact that if you hand over</p>
<p t="257253" d="2961">the management of your civilization
to machines,</p>
<p t="260214" d="3504">you then lose the incentive to understand
it yourself</p>
<p t="263718" d="2544">or to teach the next generation 
how to understand it.</p>
<p t="266262" d="3003">You can see “WALL-E”
actually as a modern version,</p>
<p t="269265" d="3628">where everyone is enfeebled
and infantilized by the machine,</p>
<p t="272893" d="1961">and that hasn’t been possible
up to now.</p>
<p t="274854" d="2419">We put a lot of our civilization 
into books,</p>
<p t="277273" d="1626">but the books can’t run it for us.</p>
<p t="278899" d="2795">And so we always have to teach
the next generation.</p>
<p t="281736" d="4212">If you work it out, it’s about a trillion
person years of teaching and learning</p>
<p t="285948" d="3962">and an unbroken chain that goes back 
tens of thousands of generations.</p>
<p t="290119" d="1919">What happens if that chain breaks?</p>
<p t="292038" d="3461">I think that’s something we have 
to understand as AI moves forward.</p>
<p t="295624" d="3587">The actual date of arrival
of general purpose AI—</p>
<p t="299211" d="3087">you’re not going to be able to pinpoint,
it isn’t a single day.</p>
<p t="302298" d="2294">It’s also not the case 
that it’s all or nothing.</p>
<p t="304592" d="2461">The impact is going to be increasing.</p>
<p t="307053" d="2043">So with every advance in AI,</p>
<p t="309096" d="2962">it significantly expands
the range of tasks.</p>
<p t="312058" d="5338">So in that sense, I think most experts say
by the end of the century,</p>
<p t="317396" d="3337">we’re very, very likely to have 
general purpose AI.</p>
<p t="320733" d="3754">The median is something around 2045.</p>
<p t="324487" d="2002">I&#39;m a little more on the
conservative side.</p>
<p t="326489" d="2085">I think the problem is
harder than we think.</p>
<p t="328574" d="3253">I like what John McAfee, 
he was one of the founders of AI,</p>
<p t="331911" d="3837">when he was asked this question, he said, 
somewhere between five and 500 years.</p>
<p t="335748" d="3337">And we&#39;re going to need, I think, several
Einsteins to make it happen.</p>
</body>
</timedtext>
