{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f17bf31-e207-4bc7-aaee-fe9ae7fe268e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This script is adapted from Corpus Approaches to Language in Social Media Online Companion (Di Cristofaro 2023), https://catlism.github.io and licensed under GPLv3.\n",
    "# Import modules for: working on local folders and files; regular expressions; finding files in a folder; reading JSON files;\n",
    "# using BeautifulSoup; working with XML files\n",
    "import os\n",
    "import re\n",
    "from glob import glob\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "from lxml import etree\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b74301-a243-45fb-8e22-21ac7148799b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a regular expression to capture the title of the video preceding yt-dlphttps://www.youtube.com/watch?v=8LHSY0zmrrU default naming conventions, where:\n",
    "# [FILENAME].info.json = the JSON file containing the metadata details\n",
    "# [FILENAME].[LL].srv3 = the XML file containing the subtitles in SRV3 format, where [LL] is the 2-letter ISO 3166-1 language code\n",
    "# The regex reads \n",
    "filename_filter = re.compile(r\"(.*?)\\.(info.json|[A-Za-z]{1,3}\\.srv3)\")\n",
    "# Create an empty list to store all the video titles\n",
    "unique_filenames_list = []\n",
    "# List all filenames present in the folder where the script resides\n",
    "files = glob(\"*.*\")\n",
    "\n",
    "# For every single filename found in the folder, do:\n",
    "for single_file in files:\n",
    "    # Search for the regular expression for capturing metadata and subtitle files in the filename, and store the result\n",
    "    # in the 'found_filename' variable\n",
    "    found_filename = re.search(filename_filter, single_file)\n",
    "    print(found_filename)\n",
    "    # If the filename matches the regular expression, extract the filename without the extensions; then check if the cleaned\n",
    "    # filename is present in the unique_filenames_list, and if not add it\n",
    "    if found_filename is not None and found_filename[1] not in unique_filenames_list:\n",
    "        unique_filenames_list.append(found_filename[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79494420-e0b5-47b9-8403-e65d64aeec56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# For each unique filename found do:\n",
    "for filename in unique_filenames_list:\n",
    "    try:\n",
    "        # Recreate the full filenames with extensions, and store each one of them into a single variable\n",
    "        json_file = filename + \".info.json\"\n",
    "        srv3_file = filename + \".\" + \"en.srv3\"\n",
    "        # Create the output filename using the input filename\n",
    "        output_xml = srv3_file + \".xml\"\n",
    "        output_txt = srv3_file + \".txt\"\n",
    "        # Create the XML element <text>, root element of the final output\n",
    "        text_tag = etree.Element(\"text\")\n",
    "    \n",
    "        print(f\"Processing {json_file}\")\n",
    "        # Open the metadata JSON file:\n",
    "        metadata_file = json.loads(open(json_file, encoding=\"utf8\").read())\n",
    "        # Read the `upload_date` datapoint in the format YYYYMMDD, and split the three values\n",
    "        # for the day, the month, and the year; then assign them to three separate attributes\n",
    "        date = datetime.strptime(metadata_file[\"upload_date\"], \"%Y%m%d\")\n",
    "        text_tag.attrib[\"date_d\"] = str(date.day)\n",
    "        text_tag.attrib[\"date_m\"] = str(date.month)\n",
    "        text_tag.attrib[\"date_y\"] = str(date.year)\n",
    "        # Check if the 'like_count' metadata point is present, if not assign the value \"na\" to the 'like_count' attribute\n",
    "\n",
    "    \n",
    "        # Assign the attribute 'format' with a value of 'srv' to the <text> element tag\n",
    "        text_tag.attrib[\"format\"] = \"srv3\"\n",
    "\n",
    "        # Add additional metadata as selected by the class:\n",
    "        text_tag.attrib[\"age_limit\"] = str(metadata_file[\"age_limit\"])\n",
    "        text_tag.attrib[\"comment_count\"] = str(metadata_file[\"comment_count\"] if \"comment_count\" in metadata_file else \"na\")\n",
    "        text_tag.attrib[\"description\"] = str(metadata_file[\"description\"])\n",
    "        text_tag.attrib[\"fulltitle\"] = str(metadata_file[\"fulltitle\"])\n",
    "        text_tag.attrib[\"like_count\"] = str(metadata_file[\"like_count\"] if \"like_count\" in metadata_file else \"na\")\n",
    "        text_tag.attrib[\"location\"] = str(metadata_file[\"location\"] if \"location\" in metadata_file else \"na\")\n",
    "        text_tag.attrib[\"playlist_title\"] = str(metadata_file[\"playlist_title\"] if \"playlist_title\" in metadata_file else \"na\")\n",
    "        text_tag.attrib[\"release_date\"] = str(metadata_file[\"release_date\"] if \"release_date\" in metadata_file else \"na\")\n",
    "        text_tag.attrib[\"upload_date\"] = str(metadata_file[\"upload_date\"])\n",
    "        text_tag.attrib[\"repost_count\"] = str(metadata_file[\"repost_count\"] if \"repost_count\" in metadata_file else \"na\")\n",
    "        tags = \"\"\n",
    "        for t in metadata_file[\"tags\"]:\n",
    "            tags += f\"{t}; \"\n",
    "        text_tag.attrib[\"tags\"] = tags\n",
    "        text_tag.attrib[\"title\"] = str(metadata_file[\"title\"])\n",
    "        text_tag.attrib[\"uploader\"] = str(metadata_file[\"uploader\"])\n",
    "        text_tag.attrib[\"view_count\"] = str(metadata_file[\"view_count\"])\n",
    "        text_tag.attrib[\"webpage_url\"] = str(metadata_file[\"webpage_url\"])\n",
    "        \n",
    "        \n",
    "        \n",
    "                    \n",
    "        print(f\"Processing {srv3_file}\")\n",
    "        # Open the SRV3 file\n",
    "        f = open(srv3_file, \"r\", encoding=\"utf8\")\n",
    "        # Parse its XML contents using BeautifulSoup\n",
    "        soup = BeautifulSoup(f, features=\"xml\")\n",
    "        # If the attribute 'ac' (= autocaption) with value '255' is found in the <s> element tag then the subtitles are the result of autocaptioning;\n",
    "        # hence assign the value 'true' to the variable 'is_ac'. Otherwise assign the value 'false' to 'is_ac'\n",
    "        if soup.body.find(\"s\", attrs={\"ac\": True}):\n",
    "            is_ac = \"true\"\n",
    "        else:\n",
    "            is_ac = \"false\"\n",
    "    \n",
    "        # Assign the value of 'is_ac' to the <text> element tag attribute 'autocaption'\n",
    "        text_tag.attrib[\"autocaption\"] = is_ac\n",
    "    \n",
    "        # Create an empty list to store all the subtitles sentences to be later saved to a \"plain-text\" file\n",
    "        plain_text = []\n",
    "    \n",
    "        # For each paragraph (i.e. each line of the subtitles) in the file do:\n",
    "        for sent in soup.body.find_all(\"p\"):\n",
    "            # Check if the textual content of the paragraph is longer than 1 character; this avoids adding empty paragraphs to the final output\n",
    "            if len(sent.get_text()) > 1:\n",
    "                # Create a <p> element tag inside the XML output\n",
    "                p_tag = etree.SubElement(text_tag, \"p\")\n",
    "                # Add the attribute 'time' (indicating the starting time of the paragraph) and assign it the value appearing in 't'\n",
    "                p_tag.attrib[\"time\"] = str(sent[\"t\"])\n",
    "                # Add the attribute 'is_ac' and assign it the value of the previously created variable 'is_ac'\n",
    "                p_tag.attrib[\"is_ac\"] = is_ac\n",
    "                p_tag.text = sent.get_text()\n",
    "                plain_text.append(sent.get_text())\n",
    "            # If the paragraph does not contain any text (i.e. its length is < 1), skip it\n",
    "            else:\n",
    "                continue\n",
    "    \n",
    "        # Write the extracted data formatted in XML to the final XML structure\n",
    "        tree = etree.ElementTree(text_tag)\n",
    "        # Write the XML to the output file\n",
    "        tree.write(\n",
    "            output_xml, pretty_print=True, xml_declaration=True, encoding=\"utf-8\"\n",
    "        )\n",
    "        \n",
    "        # Write the subtitles sentences only to a plain text file, one sentence per line\n",
    "        with open(output_txt, \"w\", encoding=\"utf8\") as o:\n",
    "        # Merge together all the sentences collected in the 'plain_text' list using a new line (\"\\n\")\n",
    "            txt_contents = \"\\n\".join(plain_text)\n",
    "        # Write the merged sentences to the final .txt file\n",
    "            o.write(txt_contents)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"FILE NOT FOUND for {json_file} and {srv3_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41e993b-e33a-46f6-a6ca-0d7b0095f0c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
