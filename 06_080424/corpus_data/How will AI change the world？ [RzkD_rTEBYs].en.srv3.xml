<?xml version='1.0' encoding='UTF-8'?>
<text title="How will AI change the world?" date_d="6" date_m="12" date_y="2022" likes="45358" format="srv3" autocaption="false">
  <p time="6335" is_ac="false">In the coming years, 
artificial intelligence</p>
  <p time="8504" is_ac="false">is probably going to change your life, 
and likely the entire world.</p>
  <p time="12592" is_ac="false">But people have a hard time
agreeing on exactly how.</p>
  <p time="15720" is_ac="false">The following are excerpts 
from a World Economic Forum interview</p>
  <p time="18931" is_ac="false">where renowned computer science professor 
and AI expert Stuart Russell</p>
  <p time="22727" is_ac="false">helps separate the sense 
from the nonsense.</p>
  <p time="25313" is_ac="false">There’s a big difference between asking
a human to do something</p>
  <p time="29067" is_ac="false">and giving that as the objective
to an AI system.</p>
  <p time="32528" is_ac="false">When you ask a human to get
you a cup of coffee,</p>
  <p time="35156" is_ac="false">you don’t mean this should be 
their life’s mission,</p>
  <p time="37742" is_ac="false">and nothing else in the universe matters.</p>
  <p time="39702" is_ac="false">Even if they have to kill everybody else
in Starbucks</p>
  <p time="42288" is_ac="false">to get you the coffee before it closes—
they should do that.</p>
  <p time="45124" is_ac="false">No, that’s not what you mean.</p>
  <p time="46751" is_ac="false">All the other things that
we mutually care about,</p>
  <p time="49045" is_ac="false">they should factor
into your behavior as well.</p>
  <p time="51214" is_ac="false">And the problem with the way 
we build AI systems now</p>
  <p time="54383" is_ac="false">is we give them a fixed objective.</p>
  <p time="56010" is_ac="false">The algorithms require us
to specify everything in the objective.</p>
  <p time="59555" is_ac="false">And if you say, can we fix the
acidification of the oceans?</p>
  <p time="62975" is_ac="false">Yeah, you could have a catalytic reaction
that does that extremely efficiently,</p>
  <p time="67021" is_ac="false">but it consumes a quarter 
of the oxygen in the atmosphere,</p>
  <p time="70274" is_ac="false">which would apparently cause us to die
fairly slowly and unpleasantly</p>
  <p time="73986" is_ac="false">over the course of several hours.</p>
  <p time="75780" is_ac="false">So, how do we avoid this problem?</p>
  <p time="78991" is_ac="false">You might say, okay, well, just be more
careful about specifying the objective—</p>
  <p time="83079" is_ac="false">don’t forget the atmospheric oxygen.</p>
  <p time="85873" is_ac="false">And then, of course, some side effect
of the reaction in the ocean</p>
  <p time="89418" is_ac="false">poisons all the fish.</p>
  <p time="90795" is_ac="false">Okay, well I meant don’t kill
the fish either.</p>
  <p time="93464" is_ac="false">And then, well, what about
the seaweed?</p>
  <p time="95383" is_ac="false">Don’t do anything that’s going
to cause all the seaweed to die.</p>
  <p time="98344" is_ac="false">And on and on and on.</p>
  <p time="99679" is_ac="false">And the reason that we don’t have to do
that with humans is that</p>
  <p time="103599" is_ac="false">humans often know that they don’t know 
all the things that we care about.</p>
  <p time="108354" is_ac="false">If you ask a human to get you
a cup of coffee,</p>
  <p time="111315" is_ac="false">and you happen to be 
in the Hotel George Sand in Paris,</p>
  <p time="114193" is_ac="false">where the coffee is 13 euros a cup,</p>
  <p time="116821" is_ac="false">it’s entirely reasonable to come
back and say, well, it’s 13 euros,</p>
  <p time="120992" is_ac="false">are you sure you want it, 
or I could go next door and get one?</p>
  <p time="123953" is_ac="false">And it’s a perfectly normal thing
for a person to do.</p>
  <p time="127039" is_ac="false">To ask, I’m going to repaint your house—</p>
  <p time="130042" is_ac="false">is it okay if I take off the drainpipes
and then put them back?</p>
  <p time="133504" is_ac="false">We don't think of this as a terribly
sophisticated capability,</p>
  <p time="136632" is_ac="false">but AI systems don’t have it 
because the way we build them now,</p>
  <p time="139719" is_ac="false">they have to know the full objective.</p>
  <p time="141721" is_ac="false">If we build systems that know that 
they don’t know what the objective is,</p>
  <p time="145474" is_ac="false">then they start to exhibit
these behaviors,</p>
  <p time="148060" is_ac="false">like asking permission before getting rid
of all the oxygen in the atmosphere.</p>
  <p time="152565" is_ac="false">In all these senses, 
control over the AI system</p>
  <p time="155943" is_ac="false">comes from the machine’s uncertainty 
about what the true objective is.</p>
  <p time="161282" is_ac="false">And it’s when you build machines that
believe with certainty</p>
  <p time="164368" is_ac="false">that they have the objective,</p>
  <p time="165786" is_ac="false">that’s when you get this
sort of psychopathic behavior.</p>
  <p time="168539" is_ac="false">And I think we see 
the same thing in humans.</p>
  <p time="170750" is_ac="false">What happens when general purpose AI
hits the real economy?</p>
  <p time="175379" is_ac="false">How do things change? Can we adapt?</p>
  <p time="179175" is_ac="false">This is a very old point.</p>
  <p time="181010" is_ac="false">Amazingly, Aristotle actually has
a passage where he says,</p>
  <p time="184597" is_ac="false">look, if we had fully automated 
weaving machines</p>
  <p time="187642" is_ac="false">and plectrums that could pluck the lyre 
and produce music without any humans,</p>
  <p time="191604" is_ac="false">then we wouldn’t need any workers.</p>
  <p time="193814" is_ac="false">That idea, which I think it was Keynes</p>
  <p time="196692" is_ac="false">who called it technological unemployment 
in 1930,</p>
  <p time="199528" is_ac="false">is very obvious to people.</p>
  <p time="201447" is_ac="false">They think, yeah, of course, 
if the machine does the work,</p>
  <p time="204533" is_ac="false">then I'm going to be unemployed.</p>
  <p time="206369" is_ac="false">You can think about the warehouses 
that companies are currently operating</p>
  <p time="209872" is_ac="false">for e-commerce, 
they are half automated.</p>
  <p time="212583" is_ac="false">The way it works is that an old warehouse—
where you’ve got tons of stuff piled up</p>
  <p time="216629" is_ac="false">all over the place 
and humans go and rummage around</p>
  <p time="219090" is_ac="false">and then bring it back and send it off—</p>
  <p time="220967" is_ac="false">there’s a robot who goes
and gets the shelving unit</p>
  <p time="224553" is_ac="false">that contains the thing that you need,</p>
  <p time="226472" is_ac="false">but the human has to pick the object 
out of the bin or off the shelf,</p>
  <p time="230101" is_ac="false">because that’s still too difficult.</p>
  <p time="232019" is_ac="false">But, at the same time,</p>
  <p time="234021" is_ac="false">would you make a robot that is accurate
enough to be able to pick</p>
  <p time="237942" is_ac="false">pretty much any object within a very wide 
variety of objects that you can buy?</p>
  <p time="242280" is_ac="false">That would, at a stroke, 
eliminate 3 or 4 million jobs?</p>
  <p time="246409" is_ac="false">There's an interesting story
that E.M. Forster wrote,</p>
  <p time="249745" is_ac="false">where everyone is entirely
machine dependent.</p>
  <p time="253499" is_ac="false">The story is really about the
fact that if you hand over</p>
  <p time="257253" is_ac="false">the management of your civilization
to machines,</p>
  <p time="260214" is_ac="false">you then lose the incentive to understand
it yourself</p>
  <p time="263718" is_ac="false">or to teach the next generation 
how to understand it.</p>
  <p time="266262" is_ac="false">You can see “WALL-E”
actually as a modern version,</p>
  <p time="269265" is_ac="false">where everyone is enfeebled
and infantilized by the machine,</p>
  <p time="272893" is_ac="false">and that hasn’t been possible
up to now.</p>
  <p time="274854" is_ac="false">We put a lot of our civilization 
into books,</p>
  <p time="277273" is_ac="false">but the books can’t run it for us.</p>
  <p time="278899" is_ac="false">And so we always have to teach
the next generation.</p>
  <p time="281736" is_ac="false">If you work it out, it’s about a trillion
person years of teaching and learning</p>
  <p time="285948" is_ac="false">and an unbroken chain that goes back 
tens of thousands of generations.</p>
  <p time="290119" is_ac="false">What happens if that chain breaks?</p>
  <p time="292038" is_ac="false">I think that’s something we have 
to understand as AI moves forward.</p>
  <p time="295624" is_ac="false">The actual date of arrival
of general purpose AI—</p>
  <p time="299211" is_ac="false">you’re not going to be able to pinpoint,
it isn’t a single day.</p>
  <p time="302298" is_ac="false">It’s also not the case 
that it’s all or nothing.</p>
  <p time="304592" is_ac="false">The impact is going to be increasing.</p>
  <p time="307053" is_ac="false">So with every advance in AI,</p>
  <p time="309096" is_ac="false">it significantly expands
the range of tasks.</p>
  <p time="312058" is_ac="false">So in that sense, I think most experts say
by the end of the century,</p>
  <p time="317396" is_ac="false">we’re very, very likely to have 
general purpose AI.</p>
  <p time="320733" is_ac="false">The median is something around 2045.</p>
  <p time="324487" is_ac="false">I'm a little more on the
conservative side.</p>
  <p time="326489" is_ac="false">I think the problem is
harder than we think.</p>
  <p time="328574" is_ac="false">I like what John McAfee, 
he was one of the founders of AI,</p>
  <p time="331911" is_ac="false">when he was asked this question, he said, 
somewhere between five and 500 years.</p>
  <p time="335748" is_ac="false">And we're going to need, I think, several
Einsteins to make it happen.</p>
</text>
