<?xml version='1.0' encoding='UTF-8'?>
<text title="The ethical dilemma of self-driving cars - Patrick Lin" date_d="8" date_m="12" date_y="2015" likes="36108" format="srv3" autocaption="false">
  <p time="7246" is_ac="false">This is a thought experiment.</p>
  <p time="9288" is_ac="false">Let's say at some point
in the not so distant future,</p>
  <p time="11913" is_ac="false">you're barreling down the highway
in your self-driving car,</p>
  <p time="15496" is_ac="false">and you find yourself boxed in
on all sides by other cars.</p>
  <p time="19788" is_ac="false">Suddenly, a large, heavy object
falls off the truck in front of you.</p>
  <p time="24204" is_ac="false">Your car can't stop in time
to avoid the collision,</p>
  <p time="27371" is_ac="false">so it needs to make a decision:</p>
  <p time="29413" is_ac="false">go straight and hit the object,</p>
  <p time="31663" is_ac="false">swerve left into an SUV,</p>
  <p time="33954" is_ac="false">or swerve right into a motorcycle.</p>
  <p time="36954" is_ac="false">Should it prioritize your safety
by hitting the motorcycle,</p>
  <p time="40454" is_ac="false">minimize danger to others by not swerving,</p>
  <p time="43246" is_ac="false">even if it means hitting the large object
and sacrificing your life,</p>
  <p time="47329" is_ac="false">or take the middle ground
by hitting the SUV,</p>
  <p time="50079" is_ac="false">which has a high passenger safety rating?</p>
  <p time="53079" is_ac="false">So what should the self-driving car do?</p>
  <p time="56287" is_ac="false">If we were driving that boxed in car
in manual mode,</p>
  <p time="59496" is_ac="false">whichever way we'd react
would be understood as just that,</p>
  <p time="63037" is_ac="false">a reaction,</p>
  <p time="64329" is_ac="false">not a deliberate decision.</p>
  <p time="66579" is_ac="false">It would be an instinctual panicked move
with no forethought or malice.</p>
  <p time="70871" is_ac="false">But if a programmer were to instruct
the car to make the same move,</p>
  <p time="74496" is_ac="false">given conditions it may 
sense in the future,</p>
  <p time="77329" is_ac="false">well, that looks more
like premeditated homicide.</p>
  <p time="81621" is_ac="false">Now, to be fair,</p>
  <p time="82621" is_ac="false">self-driving cars are predicted 
to dramatically reduce traffic accidents</p>
  <p time="86704" is_ac="false">and fatalities</p>
  <p time="87954" is_ac="false">by removing human error 
from the driving equation.</p>
  <p time="91121" is_ac="false">Plus, there may be all sorts 
of other benefits:</p>
  <p time="93496" is_ac="false">eased road congestion,</p>
  <p time="95163" is_ac="false">decreased harmful emissions,</p>
  <p time="96704" is_ac="false">and minimized unproductive
and stressful driving time.</p>
  <p time="101329" is_ac="false">But accidents can and will still happen,</p>
  <p time="103496" is_ac="false">and when they do,</p>
  <p time="104663" is_ac="false">their outcomes may be determined
months or years in advance</p>
  <p time="109163" is_ac="false">by programmers or policy makers.</p>
  <p time="111746" is_ac="false">And they'll have 
some difficult decisions to make.</p>
  <p time="114246" is_ac="false">It's tempting to offer up general 
decision-making principles,</p>
  <p time="117204" is_ac="false">like minimize harm,</p>
  <p time="119079" is_ac="false">but even that quickly leads 
to morally murky decisions.</p>
  <p time="122454" is_ac="false">For example,</p>
  <p time="123621" is_ac="false">let's say we have the same initial set up,</p>
  <p time="125621" is_ac="false">but now there's a motorcyclist 
wearing a helmet to your left</p>
  <p time="128496" is_ac="false">and another one without 
a helmet to your right.</p>
  <p time="131288" is_ac="false">Which one should 
your robot car crash into?</p>
  <p time="134371" is_ac="false">If you say the biker with the helmet
because she's more likely to survive,</p>
  <p time="138454" is_ac="false">then aren't you penalizing 
the responsible motorist?</p>
  <p time="141371" is_ac="false">If, instead, you save the biker 
without the helmet</p>
  <p time="144121" is_ac="false">because he's acting irresponsibly,</p>
  <p time="146121" is_ac="false">then you've gone way beyond the initial
design principle about minimizing harm,</p>
  <p time="150996" is_ac="false">and the robot car is now 
meting out street justice.</p>
  <p time="154871" is_ac="false">The ethical considerations 
get more complicated here.</p>
  <p time="158413" is_ac="false">In both of our scenarios,</p>
  <p time="159788" is_ac="false">the underlying design is functioning
as a targeting algorithm of sorts.</p>
  <p time="164288" is_ac="false">In other words,</p>
  <p time="165288" is_ac="false">it's systematically favoring 
or discriminating</p>
  <p time="167788" is_ac="false">against a certain type 
of object to crash into.</p>
  <p time="171288" is_ac="false">And the owners of the target vehicles</p>
  <p time="173621" is_ac="false">will suffer the negative consequences
of this algorithm</p>
  <p time="176663" is_ac="false">through no fault of their own.</p>
  <p time="178746" is_ac="false">Our new technologies are opening up
many other novel ethical dilemmas.</p>
  <p time="183413" is_ac="false">For instance, if you had to 
choose between</p>
  <p time="185496" is_ac="false">a car that would always save
as many lives as possible in an accident,</p>
  <p time="189538" is_ac="false">or one that would save you at any cost,</p>
  <p time="192579" is_ac="false">which would you buy?</p>
  <p time="194246" is_ac="false">What happens if the cars start analyzing
and factoring in</p>
  <p time="197579" is_ac="false">the passengers of the cars
and the particulars of their lives?</p>
  <p time="201038" is_ac="false">Could it be the case 
that a random decision</p>
  <p time="203204" is_ac="false">is still better than a predetermined one
designed to minimize harm?</p>
  <p time="208121" is_ac="false">And who should be making 
all of these decisions anyhow?</p>
  <p time="210829" is_ac="false">Programmers? Companies?
Governments?</p>
  <p time="214121" is_ac="false">Reality may not play out exactly
like our thought experiments,</p>
  <p time="217579" is_ac="false">but that's not the point.</p>
  <p time="219246" is_ac="false">They're designed to isolate 
and stress test our intuitions on ethics,</p>
  <p time="223579" is_ac="false">just like science experiments do
for the physical world.</p>
  <p time="226579" is_ac="false">Spotting these moral hairpin turns now</p>
  <p time="229954" is_ac="false">will help us maneuver the unfamiliar road
of technology ethics,</p>
  <p time="233538" is_ac="false">and allow us to cruise confidently
and conscientiously</p>
  <p time="237288" is_ac="false">into our brave new future.</p>
</text>
