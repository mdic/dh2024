<?xml version='1.0' encoding='UTF-8'?>
<text title="The most important century in human history" date_d="4" date_m="4" date_y="2023" likes="14729" format="srv3" autocaption="false">
  <p time="7003" is_ac="false">What's the most important century
in human history?</p>
  <p time="11049" is_ac="false">Some might argue it’s a period 
of extensive military campaigning,</p>
  <p time="14969" is_ac="false">like Alexander the Great’s 
in the 300s BCE,</p>
  <p time="18848" is_ac="false">which reshaped political
and cultural borders.</p>
  <p time="23936" is_ac="false">Others might cite the emergence 
of a major religion,</p>
  <p time="27023" is_ac="false">such as Islam in the 7th century,</p>
  <p time="29525" is_ac="false">which codified and spread values
across such borders.</p>
  <p time="35531" is_ac="false">Or perhaps it’s the Industrial Revolution
of the 1700s</p>
  <p time="38993" is_ac="false">that transformed global commerce</p>
  <p time="40745" is_ac="false">and redefined humanity's relationship
with labor.</p>
  <p time="44165" is_ac="false">Whatever the answer, it seems like 
any century vying for that top spot</p>
  <p time="48294" is_ac="false">is at a moment of great change—</p>
  <p time="51631" is_ac="false">when the actions of our ancestors shifted
humanity’s trajectory</p>
  <p time="55802" is_ac="false">for centuries to come.</p>
  <p time="57720" is_ac="false">So if this is our metric, 
is it possible that right now—</p>
  <p time="61641" is_ac="false">this century— 
is the most important one yet?</p>
  <p time="65770" is_ac="false">The 21st century has already proven to be
a period of rapid technological growth.</p>
  <p time="71234" is_ac="false">Phones and computers have accelerated
the pace of life.</p>
  <p time="74403" is_ac="false">And we’re likely on the cusp of developing
new transformative technologies,</p>
  <p time="78574" is_ac="false">like advanced artificial intelligence,</p>
  <p time="80868" is_ac="false">that could entirely change 
the way people live.</p>
  <p time="85414" is_ac="false">Meanwhile, many technologies 
we already have</p>
  <p time="88459" is_ac="false">contribute to humanity’s unprecedented 
levels of existential risk—</p>
  <p time="93381" is_ac="false">that’s the risk of our
species going extinct</p>
  <p time="95758" is_ac="false">or experiencing some kind of disaster
that permanently limits</p>
  <p time="99178" is_ac="false">humanity’s ability to grow and thrive.</p>
  <p time="103266" is_ac="false">The invention of the atomic bomb marked
a major rise in existential risk,</p>
  <p time="108396" is_ac="false">and since then we’ve only increased
the odds against us.</p>
  <p time="112900" is_ac="false">It’s profoundly difficult
to estimate the odds</p>
  <p time="115528" is_ac="false">of an existential collapse 
occurring this century.</p>
  <p time="118239" is_ac="false">Very rough guesses put the risk 
of existential catastrophe</p>
  <p time="121701" is_ac="false">due to nuclear winter and climate change
at around 0.1%,</p>
  <p time="128291" is_ac="false">with the odds of a pandemic causing
the same kind of collapse</p>
  <p time="131502" is_ac="false">at a frightening 3%.</p>
  <p time="134005" is_ac="false">Given that any of these disasters could 
mean the end of life as we know it,</p>
  <p time="139177" is_ac="false">these aren’t exactly small figures,</p>
  <p time="141304" is_ac="false">And it’s possible this century could see
the rise of new technologies</p>
  <p time="145308" is_ac="false">that introduce more existential risks.</p>
  <p time="149103" is_ac="false">AI experts have a wide range 
of estimates regarding</p>
  <p time="151731" is_ac="false">when artificial general intelligence
will emerge,</p>
  <p time="154734" is_ac="false">but according to some surveys,
many believe it could happen this century.</p>
  <p time="159655" is_ac="false">Currently, we have relatively narrow forms
of artificial intelligence,</p>
  <p time="163492" is_ac="false">which are designed to do specific tasks 
like play chess or recognize faces.</p>
  <p time="169040" is_ac="false">Even narrow AIs that do creative work are
limited to their singular specialty.</p>
  <p time="174503" is_ac="false">But artificial general intelligences,
or AGIs,</p>
  <p time="178132" is_ac="false">would be able to adapt to and
perform any number of tasks,</p>
  <p time="182678" is_ac="false">quickly outpacing 
their human counterparts.</p>
  <p time="186849" is_ac="false">There are a huge variety of guesses
about what AGI could look like,</p>
  <p time="191646" is_ac="false">and what it would mean
for humanity to share the Earth</p>
  <p time="194482" is_ac="false">with another sentient entity.</p>
  <p time="198653" is_ac="false">AGIs might help us achieve our goals,</p>
  <p time="201197" is_ac="false">they might regard us as inconsequential,</p>
  <p time="203491" is_ac="false">or, they might see us as an obstacle
to swiftly remove.</p>
  <p time="206869" is_ac="false">So in terms of existential risk,</p>
  <p time="209038" is_ac="false">it's imperative the values of this new
technology align with our own.</p>
  <p time="213501" is_ac="false">This is an incredibly difficult
philosophical and engineering challenge</p>
  <p time="217380" is_ac="false">that will require a lot 
of delicate, thoughtful work.</p>
  <p time="220967" is_ac="false">Yet, even if we succeed, AGI could still
lead to another complicated outcome.</p>
  <p time="226847" is_ac="false">Let’s imagine an AGI emerges 
with deep respect for human life</p>
  <p time="230643" is_ac="false">and a desire to solve
all humanity’s troubles.</p>
  <p time="235231" is_ac="false">But to avoid becoming misaligned,</p>
  <p time="237400" is_ac="false">it's been developed to be incredibly
rigid about its beliefs.</p>
  <p time="241237" is_ac="false">If these machines became 
the dominant power on Earth,</p>
  <p time="244323" is_ac="false">their strict values might
become hegemonic,</p>
  <p time="247034" is_ac="false">locking humanity into one ideology that
would be incredibly resistant to change.</p>
  <p time="254792" is_ac="false">History has taught us that
no matter how enlightened</p>
  <p time="257295" is_ac="false">a civilization thinks they are,</p>
  <p time="259088" is_ac="false">they are rarely up to the moral standards
of later generations.</p>
  <p time="263009" is_ac="false">And this kind of value lock in
could permanently distort or constrain</p>
  <p time="267638" is_ac="false">humanity’s moral growth.</p>
  <p time="270016" is_ac="false">There's a ton of uncertainty around AGI,</p>
  <p time="272601" is_ac="false">and it’s profoundly difficult to predict
how any existential risks</p>
  <p time="276314" is_ac="false">will play out over the next century.</p>
  <p time="278649" is_ac="false">It’s also possible that new, 
more pressing concerns</p>
  <p time="281569" is_ac="false">might render these risks moot.</p>
  <p time="283904" is_ac="false">But even if we can't definitively say that
ours is the most important century,</p>
  <p time="288617" is_ac="false">it still seems like the decisions 
we make might have a major impact</p>
  <p time="292371" is_ac="false">on humanity’s future.</p>
  <p time="294415" is_ac="false">So maybe we should all live 
like the future depends on us—</p>
  <p time="297626" is_ac="false">because actually, it just might.</p>
</text>
