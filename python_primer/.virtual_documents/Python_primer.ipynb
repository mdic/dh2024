





# This is a single-line comment

"""
This is a
multiline
comment
"""

















# the following code has a hierarchy, whereby `print(c)` is a child of `for c in "example"`
for c in "example":
    print(c)








w = 1
x = -3255522
y = 1.09834
z = -20.976362

print(type(w))
print(type(x))
print(type(y))
print(type(z))





text = "This is a sample sentence."

for c in text:
    print(c)





for c in text.split():
    print(c)





ingredients = ["chicken", "curry spices", "yoghurt", "coconut milk"]





for i in ingredients:
    print(i)





# Lists are ordered and indexed

print(ingredients[1])


# Lists are changeable
ingredients[2] = "vegan yoghurt"
print(ingredients)


# Lists may contain duplicate values
ingredients.append("chicken")
# we need A LOT of chicken!
print(ingredients)


# How many items are in a list?
print(len(ingredients))





shopping_list = {
    "chicken": "1 whole",
    "curry spices": "150gr",
    "yoghurt": "200gr",
    "coconut milk": "400ml",
}

print(shopping_list)


# Dictionaries are ordered
print(shopping_list["chicken"])


# Dictionaries are changeable
shopping_list["yoghurt"] = "400gr"
print(shopping_list)


# Dictionaries do not allow duplicates
shopping_list = {
    "chicken": "1 whole",
    "curry spices": "150gr",
    "yoghurt": "200gr",
    "coconut milk": "400ml",
    "coconut milk": "300ml",
}

print(shopping_list)


# How many items are in a dictionary?
print(len(shopping_list))











import os
print(os.getcwd())
with open("./python_primer/data/ABERCROMBIE_FITCH__AR__NYSE_ANF_2022.txt", "r") as text:
    print(text)
    


with open("./python_primer/data/ABERCROMBIE_FITCH__AR__NYSE_ANF_2022.txt", "r") as text:
    print(text)





from glob import glob

files = glob("./python_primer/data/*.txt")

for file in files:
    text = open(file, "r").read()
    print(text)





with open("output.txt", "w") as out:
    out.write()


with open("output_continuous.txt", "a") as out:
    out.write()














from lingua import Language, LanguageDetectorBuilder
from glob import glob
import re

# Setup some variables and parameters to be later used
languages = [Language.ENGLISH, Language.FRENCH]
detector = LanguageDetectorBuilder.from_languages(*languages).build()


posts = glob("./data/instagram/*.txt")

for post in posts:
    f = open(post, "r").readlines()
    for line in f:
        lang = detector.detect_language_of(line)
        print(f"TEXT::{line}\nLANG::{lang}\n")
        





import emoji

# Define a custom function to transliterate emojis and add curly brackets as delimites for the CLDR

def demoji(chars, data_dict):
    trans = emoji.demojize(chars, delimiters=("{", "}"))
    return trans


posts = glob("./data/instagram/*.txt")

for post in posts:
    f = open(post, "r").readlines()
    for line in f:
        line = emoji.replace_emoji(line, replace=lambda chars, data_dict: demoji(chars,data_dict))
        print(line)





import re
import wordsegment

wordsegment.load()
hashtag_re = re.compile("(?:^|\s)([ï¼ƒ#]{1})(\w+)", re.UNICODE)


posts = glob("./data/instagram/*.txt")

for post in posts:
    f = open(post, "r").read()
    segmented_hastags = ""
    for hashtag in re.findall(hashtag_re, f):
        found_hashtag = "".join(hashtag)
        clean_hashtag = hashtag[1]
        segmented = " ".join(wordsegment.segment(clean_hashtag))
        tag = f"<exhashtag original='{clean_hashtag}'>{segmented}</exhashtag>"
        f = f.replace(found_hashtag, tag)
    print(f)
